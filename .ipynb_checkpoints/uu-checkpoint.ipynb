{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d0282d6-1499-4837-a05d-ca2c8d3a9c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF_XLA_FLAGS: --tf_xla_enable_xla_devices=false\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Deshabilitar XLA para ver si se estabiliza\n",
    "os.environ[\"TF_XLA_FLAGS\"] = \"--tf_xla_enable_xla_devices=false\"\n",
    "print(\"TF_XLA_FLAGS:\", os.environ.get(\"TF_XLA_FLAGS\"))\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import zipfile\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "from PIL import UnidentifiedImageError\n",
    "from tqdm import tqdm \n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4d94f39-e24d-421c-88e5-3e73768f8968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Preprocesamiento del Dataset\n",
    "# Definir el directorio donde se encuentran las imágenes del dataset\n",
    "with zipfile.ZipFile('pokemon.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('pokemos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b16e415-61fe-430e-9577-8f7434dc8391",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"pokemos/PokemonData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78992059-b723-4c2c-afec-0997c4601302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imágenes después de filtrar: 11945\n",
      "Número de imágenes cargadas inicialmente: 11945\n",
      "Número de etiquetas cargadas inicialmente: 11945\n"
     ]
    }
   ],
   "source": [
    "# Paso 1: Preprocesamiento del Dataset\n",
    "# Parámetros de preprocesamiento\n",
    "IMG_SIZE = (224, 224)  # Tamaño al que se redimensionarán las imágenes\n",
    "BATCH_SIZE = 32  # Tamaño del lote para preprocesamiento\n",
    "\n",
    "# Listar todas las imágenes en el directorio\n",
    "image_files = []\n",
    "labels = []\n",
    "for root, _, files in os.walk(dataset_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('jpg', 'jpeg', 'png')):\n",
    "            image_files.append(os.path.join(root, file))\n",
    "            labels.append(os.path.basename(root))\n",
    "\n",
    "# Convertir listas de archivos y etiquetas a tensores\n",
    "image_files = tf.constant(image_files)\n",
    "labels = tf.constant(labels)\n",
    "\n",
    "# Filtrar clases con al menos 2 ejemplos\n",
    "label_counts = Counter(labels.numpy())\n",
    "valid_labels = [label for label, count in label_counts.items() if count >= 2]\n",
    "filtered_image_files = []\n",
    "filtered_labels = []\n",
    "for img, label in zip(image_files.numpy(), labels.numpy()):\n",
    "    if label in valid_labels:\n",
    "        filtered_image_files.append(img)\n",
    "        filtered_labels.append(label)\n",
    "\n",
    "image_files = tf.constant(filtered_image_files)\n",
    "labels = tf.constant(filtered_labels)\n",
    "\n",
    "print(f\"Total de imágenes después de filtrar: {len(image_files)}\")\n",
    "\n",
    "\n",
    "# Codificar las etiquetas para que sean valores enteros\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels.numpy())\n",
    "\n",
    "# Convertir etiquetas a tensor de TensorFlow\n",
    "labels = tf.constant(labels)\n",
    "\n",
    "# Crear un dataset de TensorFlow con las rutas de las imágenes y etiquetas\n",
    "def parse_function(filename, label):\n",
    "    # Leer el archivo de imagen\n",
    "    img = tf.io.read_file(filename)\n",
    "    # Decodificar la imagen\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Redimensionar la imagen\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    # Normalizar los valores de los píxeles entre 0 y 1\n",
    "    img = img / 255.0\n",
    "    return img, label\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_files, labels))\n",
    "dataset = dataset.map(parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "#dataset = dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "print(f\"Número de imágenes cargadas inicialmente: {len(image_files)}\")\n",
    "print(f\"Número de etiquetas cargadas inicialmente: {len(labels)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7831f636-76f7-4c6a-893e-5b02c8bbb795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividiendo el dataset en conjuntos de entrenamiento, validación y prueba...\n",
      "Número total de muestras en el dataset: 11945\n",
      "Tamaño del conjunto de Entrenamiento: 8361\n",
      "Tamaño del conjunto de Validación: 2389\n",
      "Tamaño del conjunto de Prueba: 1195\n",
      "Tamaño del conjunto de Entrenamiento (número de lotes): 262\n",
      "Tamaño del conjunto de Validación (número de lotes): 75\n",
      "Tamaño del conjunto de Prueba (número de lotes): 38\n"
     ]
    }
   ],
   "source": [
    "# Paso 2: División del Dataset\n",
    "print(\"Dividiendo el dataset en conjuntos de entrenamiento, validación y prueba...\")\n",
    "dataset = dataset.shuffle(len(image_files), reshuffle_each_iteration=False)\n",
    "dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n",
    "print(f\"Número total de muestras en el dataset: {dataset_size}\")\n",
    "train_size = int(0.7 * len(image_files))\n",
    "val_size = int(0.2 * len(image_files))\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "print(f\"Tamaño del conjunto de Entrenamiento: {train_size}\")\n",
    "print(f\"Tamaño del conjunto de Validación: {val_size}\")\n",
    "print(f\"Tamaño del conjunto de Prueba: {test_size}\")\n",
    "\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_test_dataset = dataset.skip(train_size)\n",
    "val_dataset = val_test_dataset.take(val_size)\n",
    "test_dataset = val_test_dataset.skip(val_size)\n",
    "\"\"\"\n",
    "# Definir la función de data augmentation\n",
    "def augment(image, label):\n",
    "    # Aplicar transformaciones aleatorias\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
    "    image = tf.image.random_saturation(image, lower=0.9, upper=1.1)\n",
    "    image = tf.image.random_hue(max_delta=0.1)\n",
    "    # Asegurarse de que la imagen sigue en el rango [0, 1]\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    return image, label\n",
    "\n",
    "# Aplicar data augmentation solo al conjunto de entrenamiento\n",
    "train_dataset = train_dataset.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\"\"\"\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "print(f\"Tamaño del conjunto de Entrenamiento (número de lotes): {tf.data.experimental.cardinality(train_dataset).numpy()}\")\n",
    "print(f\"Tamaño del conjunto de Validación (número de lotes): {tf.data.experimental.cardinality(val_dataset).numpy()}\")\n",
    "print(f\"Tamaño del conjunto de Prueba (número de lotes): {tf.data.experimental.cardinality(test_dataset).numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8280c01c-fb4d-4bdf-bb34-e74eae686863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurando el modelo MobileNetV2 para entrenamiento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_49453/3739781872.py:5: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=input_tensor)\n"
     ]
    }
   ],
   "source": [
    "# Paso 3: Entrenamiento del Modelo con MobileNetV2\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "print(\"Configurando el modelo MobileNetV2 para entrenamiento...\")\n",
    "input_tensor = Input(shape=(224, 224, 3))  # Usando 3 canales ya que las imágenes son ahora \"RGB\"\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=input_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b448fd6-ff30-4005-aaa1-becb1604882a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el modelo...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_157']\n",
      "Received: inputs=Tensor(shape=(None, 224, 224, 3))\n",
      "  warnings.warn(msg)\n",
      "/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_157']\n",
      "Received: inputs=Tensor(shape=(None, 224, 224, 3))\n",
      "  warnings.warn(msg)\n",
      "2025-02-02 01:12:04.527784: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:450] ShuffleDatasetV3:16: Filling up shuffle buffer (this may take a while): 9762 of 11945\n",
      "2025-02-02 01:12:06.896127: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:480] Shuffle buffer filled.\n",
      "W0000 00:00:1738476728.218497   49728 gpu_backend_lib.cc:617] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2025-02-02 01:12:08.233447: W tensorflow/core/framework/op_kernel.cc:1841] OP_REQUIRES failed at xla_ops.cc:577 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2025-02-02 01:12:08.233528: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "\t [[{{node StatefulPartitionedCall}}]]\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/runpy.py\", line 88, in _run_code\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_49453/514706171.py\", line 39, in <module>\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_16958]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntrenando el modelo...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpruning_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/ml_env/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/runpy.py\", line 198, in _run_module_as_main\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/runpy.py\", line 88, in _run_code\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n\n  File \"/tmp/ipykernel_49453/514706171.py\", line 39, in <module>\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/home/pibezx/miniconda3/envs/ml_env/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node StatefulPartitionedCall}}]] [Op:__inference_multi_step_on_iterator_16958]"
     ]
    }
   ],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "# Congelar las capas base de MobileNetV2 para transfer learning\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Parámetros para pruning\n",
    "prune_low_magnitude = tfmt.sparsity.keras.prune_low_magnitude\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmt.sparsity.keras.PolynomialDecay(\n",
    "        initial_sparsity=0.0, \n",
    "        final_sparsity=0.5, \n",
    "        begin_step=0, \n",
    "        end_step=7860\n",
    "    )\n",
    "}\n",
    "# Añadir capas personalizadas\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Promedio global para reducir dimensiones\n",
    "x = Dense(128, activation='relu')(x)  # Capa totalmente conectada\n",
    "predictions = Dense(len(valid_labels), activation='softmax')(x)  # Capa de salida\n",
    "\n",
    "# Crear el modelo final\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Añadir Early Stopping para prevenir el sobreajuste\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Añadir callback para el pruning\n",
    "pruning_callback = tfmt.sparsity.keras.UpdatePruningStep()\n",
    "\n",
    "# Calcular steps_per_epoch\n",
    "steps_per_epoch = np.ceil(train_size / BATCH_SIZE).astype(int)\n",
    "\n",
    "# Entrenar el modelo\n",
    "print(\"Entrenando el modelo...\")\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=30,\n",
    "    callbacks=[early_stopping, pruning_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24116d-b797-475e-b28a-683aa91e243e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_env)",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
